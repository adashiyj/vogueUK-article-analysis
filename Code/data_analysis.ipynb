{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5076fa0b-fcec-4f86-a254-e027d5dea8f5",
   "metadata": {
    "id": "5076fa0b-fcec-4f86-a254-e027d5dea8f5"
   },
   "source": [
    "# Data analysis\n",
    "### Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cd0ff94-efe1-46cd-b32e-25c3d3680ab3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9cd0ff94-efe1-46cd-b32e-25c3d3680ab3",
    "outputId": "979c46e9-9aa0-4d3f-d8a3-a4278601d008"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d15219-3ed6-484e-a6ed-4d98d59d584e",
   "metadata": {
    "id": "d7d15219-3ed6-484e-a6ed-4d98d59d584e"
   },
   "outputs": [],
   "source": [
    "# pd.set_option(\"display.max_colwidth\", None) # turn ON full text\n",
    "# pd.reset_option(\"display.max_colwidth\") # turn OFF full text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451cf120-b68f-4bb0-90d7-1b70cd7d9258",
   "metadata": {
    "id": "451cf120-b68f-4bb0-90d7-1b70cd7d9258"
   },
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "091ee3c1-53ab-4d07-b003-1b4f3ecad6a4",
   "metadata": {
    "id": "091ee3c1-53ab-4d07-b003-1b4f3ecad6a4"
   },
   "outputs": [],
   "source": [
    "df_comments = pd.read_csv(\"youtube_comments_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34qdhSnWIuxj",
   "metadata": {
    "id": "34qdhSnWIuxj"
   },
   "outputs": [],
   "source": [
    "# Add columns to track labels\n",
    "df_comments['relevance_label'] = np.nan  # Step 1: relevant = 1 / irrelevant = 0\n",
    "df_comments['agree_label'] = np.nan      # Step 2: agree = 1 / neutral = 0 / disagree = -1\n",
    "df_comments['dataset_split'] = np.nan    # Track train/val/test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "E4YxMToYCp1G",
   "metadata": {
    "id": "E4YxMToYCp1G"
   },
   "source": [
    "### Split the dataset into Train-Val-Test (60-20-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "wGIUHpFQI4N_",
   "metadata": {
    "id": "wGIUHpFQI4N_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 3966 Val: 1322 Test: 1322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kw/83vtrb5s4k5g0zx9zp814ky00000gn/T/ipykernel_53267/1152913637.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'train' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_comments.loc[train.index, 'dataset_split'] = 'train'\n"
     ]
    }
   ],
   "source": [
    "# Shuffle dataset\n",
    "df_comments = df_comments.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Split data into training and test sets\n",
    "train_val, test = train_test_split(df_comments, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split training data into training and validation sets\n",
    "train, val = train_test_split(train_val, test_size=0.25, random_state=42)\n",
    "\n",
    "# Assign dataset_split column\n",
    "df_comments.loc[train.index, 'dataset_split'] = 'train'\n",
    "df_comments.loc[val.index, 'dataset_split'] = 'val'\n",
    "df_comments.loc[test.index, 'dataset_split'] = 'test'\n",
    "\n",
    "print(\"Train:\", len(train), \"Val:\", len(val), \"Test:\", len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xTj6DzScDcxA",
   "metadata": {
    "id": "xTj6DzScDcxA"
   },
   "source": [
    "## Step 1: Relevance Classification (Relevant vs Irrelevant)\n",
    "### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pnuHZveKDXrT",
   "metadata": {
    "id": "pnuHZveKDXrT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported 1000 comments for manual relevance labeling.\n"
     ]
    }
   ],
   "source": [
    "# Sample 1000 unlabeled comments from train\n",
    "sample_to_label = df_comments[(df_comments['dataset_split']=='train') & (df_comments['relevance_label'].isna())].sample(1000, random_state=42)\n",
    "\n",
    "# Keep original comment for labeling\n",
    "sample_to_label_export = sample_to_label[['comment']].copy()\n",
    "sample_to_label_export['relevance_label'] = \"\"  # empty column to fill manually\n",
    "\n",
    "# Export to Excel for manual labeling\n",
    "sample_to_label_export.to_excel(\"relevance_label_sample.xlsx\", index=False)\n",
    "print(\"Exported 1000 comments for manual relevance labeling.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kkHVO6xcMK9a",
   "metadata": {
    "id": "kkHVO6xcMK9a"
   },
   "source": [
    "### Run the code below after completing manual labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d224d605-b51c-491f-9af1-1e0c420343c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the labled EXCEL file\n",
    "labeled_relevance = pd.read_excel(\"relevance_label_sample.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "142f3655-0dad-4cae-8b1f-9065a06b8e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the labels back into df_comments\n",
    "df_comments_merged1 = df_comments.merge(\n",
    "    labeled_relevance,\n",
    "    on=\"clean_comment\",\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ba4d816-f2fe-4236-956f-2d686b4ddbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the CSV\n",
    "df_comments_merged1.to_csv(\"youtube_comments_relevance_labled.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f36d8b-1aac-402e-ad80-2ecda501a88d",
   "metadata": {},
   "source": [
    "**Note:** Although I manually labeled 1000 comments for the first step of SML, after merging the labels back into the main dataset, only 973 labeled comments remained. This is because some comments in the dataset are duplicated, and duplicates were removed during the merge to ensure each comment has a unique label for training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "L2Ssd7MPMbOr",
   "metadata": {
    "id": "L2Ssd7MPMbOr"
   },
   "source": [
    "### Train BERT for step 1 (relevance) classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "sHuy0LXoMi3a",
   "metadata": {
    "id": "sHuy0LXoMi3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled comments available for training: 973\n"
     ]
    }
   ],
   "source": [
    "# Only keep rows with labels for training\n",
    "df_labeled = df_comments_merged1[df_comments_merged1['relevance_label'].notna()].copy()\n",
    "print(f\"Labeled comments available for training: {len(df_labeled)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6ee893f9-a511-4f7c-816e-273ec35a583c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns for SML\n",
    "df = df_labeled[['clean_comment', 'relevance_label']].dropna()\n",
    "\n",
    "# Ensure label is integer\n",
    "df['relevance_label'] = df['relevance_label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b8d693-0459-439c-bc8a-079797dae6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train, validation, test (e.g., 70-15-15)\n",
    "texts = df['clean_comment'].tolist()\n",
    "labels = df['relevance_label'].tolist()\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    texts, labels, test_size=0.15, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=0.1765, random_state=42, stratify=y_train_val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8906e8ba-8887-495e-8fd4-26f57111eea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Hugging Face Dataset\n",
    "train_dataset = Dataset.from_dict({'text': X_train, 'label': y_train})\n",
    "val_dataset = Dataset.from_dict({'text': X_val, 'label': y_val})\n",
    "test_dataset = Dataset.from_dict({'text': X_test, 'label': y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f871ee44-5963-4224-9b2b-86f7af042304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding=True, truncation=True, max_length=128)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize, batched=True)\n",
    "\n",
    "# Set format for PyTorch\n",
    "train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "val_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b8080c-cd93-4dd0-810c-a8ad2ec617e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BERT model\n",
    "num_labels = 2  # relevance: 1 = relevant, 0 = irrelevant\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # automatically choose GPU if available, otherwise use CPU\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86873870-d786-452b-8442-3df2300f350b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"WANDB_MODE\"] = \"offline\"\n",
    "\n",
    "metric_name = \"accuracy\" # you can change this for macro f1 etc\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    # Where to save model + checkpoints\n",
    "    output_dir=\"./results\",\n",
    "\n",
    "    # Training setup\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=5e-5,\n",
    "    warmup_steps=0,\n",
    "    weight_decay=0.01,\n",
    "\n",
    "    # Logging\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=20,\n",
    "\n",
    "    # Evaluation & saving\n",
    "    eval_strategy=\"steps\",   # evaluate every eval_steps\n",
    "    eval_steps=50,\n",
    "    save_strategy=\"steps\",   # save checkpoint every save_steps\n",
    "    save_steps=50,\n",
    "\n",
    "    # Best-model loading\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    "    greater_is_better=True,\n",
    "\n",
    "    # Run on CPU or GPU automatically (Trainer + accelerate handle this)\n",
    "    # You don't need to set device manually here\n",
    ")\n",
    "\n",
    "# Define metrics\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    labels = p.label_ids\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {'accuracy': acc, 'f1': f1, 'precision': precision, 'recall': recall}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=val_dataset,           # evaluation dataset (usually a validation set; here we just send our test set)\n",
    "    compute_metrics=compute_metrics      # our custom evaluation function\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2262b7df-35a4-4ea8-b4f3-a34c587bb7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "trainer.save_model(save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ffba72-ca64-4580-b0b1-d97f9691644b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the test set\n",
    "trainer.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SUe3OaMlMzpM",
   "metadata": {
    "id": "SUe3OaMlMzpM"
   },
   "source": [
    "## Step 2: Sentiment/Agreement Classification (Agree/Neutral/Disagree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nnevqXG7M4lu",
   "metadata": {
    "id": "nnevqXG7M4lu"
   },
   "outputs": [],
   "source": [
    "# Filter the relevant comments\n",
    "relevant_comments = df_comments[df_comments['relevance_label']==1]  # or predicted 1 if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OLCGGjXzNFXv",
   "metadata": {
    "id": "OLCGGjXzNFXv"
   },
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FS351LYoNA01",
   "metadata": {
    "id": "FS351LYoNA01"
   },
   "outputs": [],
   "source": [
    "sample_agree = relevant_comments.sample(300, random_state=42)\n",
    "sample_agree_export = sample_agree[['comment']].copy()\n",
    "sample_agree_export['agree_label'] = \"\"  # empty for manual labeling\n",
    "sample_agree_export.to_excel(\"agree_label_sample.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Pqvn2brMBu6U",
   "metadata": {
    "id": "Pqvn2brMBu6U"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
