{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5076fa0b-fcec-4f86-a254-e027d5dea8f5",
   "metadata": {
    "id": "5076fa0b-fcec-4f86-a254-e027d5dea8f5"
   },
   "source": [
    "# Data analysis\n",
    "- Step 1: Relevance Classification (Relevant vs Irrelevant)\n",
    "- Step 2: Agreement Classification (Agree/Neutral/Disagree)\n",
    "### Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd0ff94-efe1-46cd-b32e-25c3d3680ab3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9cd0ff94-efe1-46cd-b32e-25c3d3680ab3",
    "outputId": "979c46e9-9aa0-4d3f-d8a3-a4278601d008"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import os\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "from bertopic import BERTopic\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d15219-3ed6-484e-a6ed-4d98d59d584e",
   "metadata": {
    "id": "d7d15219-3ed6-484e-a6ed-4d98d59d584e"
   },
   "outputs": [],
   "source": [
    "# pd.set_option(\"display.max_colwidth\", None) # turn ON full text\n",
    "# pd.reset_option(\"display.max_colwidth\") # turn OFF full text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451cf120-b68f-4bb0-90d7-1b70cd7d9258",
   "metadata": {
    "id": "451cf120-b68f-4bb0-90d7-1b70cd7d9258"
   },
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091ee3c1-53ab-4d07-b003-1b4f3ecad6a4",
   "metadata": {
    "id": "091ee3c1-53ab-4d07-b003-1b4f3ecad6a4"
   },
   "outputs": [],
   "source": [
    "df_comments = pd.read_csv(\"youtube_comments_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34qdhSnWIuxj",
   "metadata": {
    "id": "34qdhSnWIuxj"
   },
   "outputs": [],
   "source": [
    "# Add columns to track labels\n",
    "df_comments['relevance_label'] = np.nan  # Step 1: relevant = 1 / irrelevant = 0\n",
    "df_comments['agree_label'] = np.nan      # Step 2: agree = 1 / neutral = 0 / disagree = -1\n",
    "df_comments['dataset_split'] = np.nan    # Track train/val/test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "E4YxMToYCp1G",
   "metadata": {
    "id": "E4YxMToYCp1G"
   },
   "source": [
    "### Split the dataset into Train-Val-Test (60-20-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wGIUHpFQI4N_",
   "metadata": {
    "id": "wGIUHpFQI4N_"
   },
   "outputs": [],
   "source": [
    "# Shuffle dataset\n",
    "df_comments = df_comments.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Split data into training and test sets\n",
    "train_val, test = train_test_split(df_comments, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split training data into training and validation sets\n",
    "train, val = train_test_split(train_val, test_size=0.25, random_state=42)\n",
    "\n",
    "# Assign dataset_split column\n",
    "df_comments.loc[train.index, 'dataset_split'] = 'train'\n",
    "df_comments.loc[val.index, 'dataset_split'] = 'val'\n",
    "df_comments.loc[test.index, 'dataset_split'] = 'test'\n",
    "\n",
    "print(\"Train:\", len(train), \"Val:\", len(val), \"Test:\", len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xTj6DzScDcxA",
   "metadata": {
    "id": "xTj6DzScDcxA"
   },
   "source": [
    "## Step 1: Relevance Classification (Relevant vs Irrelevant)\n",
    "### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pnuHZveKDXrT",
   "metadata": {
    "id": "pnuHZveKDXrT"
   },
   "outputs": [],
   "source": [
    "# Sample 1000 unlabeled comments from train\n",
    "sample_to_label = df_comments[(df_comments['dataset_split']=='train') & (df_comments['relevance_label'].isna())].sample(1000, random_state=42)\n",
    "\n",
    "# Keep original comment for labeling\n",
    "sample_to_label_export = sample_to_label[['comment']].copy()\n",
    "sample_to_label_export['relevance_label'] = \"\"  # empty column to fill manually\n",
    "\n",
    "# Export to Excel for manual labeling\n",
    "sample_to_label_export.to_excel(\"relevance_label_sample.xlsx\", index=False)\n",
    "print(\"Exported 1000 comments for manual relevance labeling.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kkHVO6xcMK9a",
   "metadata": {
    "id": "kkHVO6xcMK9a"
   },
   "source": [
    "### Run the code below after completing manual labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d224d605-b51c-491f-9af1-1e0c420343c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the labled EXCEL file\n",
    "labeled_relevance = pd.read_excel(\"relevance_label_sample.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142f3655-0dad-4cae-8b1f-9065a06b8e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the labels back into df_comments\n",
    "df_comments_merged1 = df_comments.merge(\n",
    "    labeled_relevance,\n",
    "    on=\"clean_comment\",\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba4d816-f2fe-4236-956f-2d686b4ddbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the CSV\n",
    "df_comments_merged1.to_csv(\"youtube_comments_relevance_labled.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f36d8b-1aac-402e-ad80-2ecda501a88d",
   "metadata": {},
   "source": [
    "**Note:** Although I manually labeled 1000 comments for the first step of SML, after merging the labels back into the main dataset, only 973 labeled comments remained. This is because some comments in the dataset are duplicated, and duplicates were removed during the merge to ensure each comment has a unique label for training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "L2Ssd7MPMbOr",
   "metadata": {
    "id": "L2Ssd7MPMbOr"
   },
   "source": [
    "### Train BERT for step 1 (relevance) classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sHuy0LXoMi3a",
   "metadata": {
    "id": "sHuy0LXoMi3a"
   },
   "outputs": [],
   "source": [
    "# Only keep rows with labels for training\n",
    "df_labeled = df_comments_merged1[df_comments_merged1['relevance_label'].notna()].copy()\n",
    "print(f\"Labeled comments available for training: {len(df_labeled)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee893f9-a511-4f7c-816e-273ec35a583c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns for SML\n",
    "df = df_labeled[['clean_comment', 'relevance_label']].dropna()\n",
    "\n",
    "# Ensure label is integer\n",
    "df['relevance_label'] = df['relevance_label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b8d693-0459-439c-bc8a-079797dae6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train, validation, test (e.g., 70-15-15)\n",
    "texts = df['clean_comment'].tolist()\n",
    "labels = df['relevance_label'].tolist()\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    texts, labels, test_size=0.15, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=0.1765, random_state=42, stratify=y_train_val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8906e8ba-8887-495e-8fd4-26f57111eea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Hugging Face Dataset\n",
    "train_dataset = Dataset.from_dict({'text': X_train, 'label': y_train})\n",
    "val_dataset = Dataset.from_dict({'text': X_val, 'label': y_val})\n",
    "test_dataset = Dataset.from_dict({'text': X_test, 'label': y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f871ee44-5963-4224-9b2b-86f7af042304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding=True, truncation=True, max_length=128)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize, batched=True)\n",
    "\n",
    "# Set format for PyTorch\n",
    "train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "val_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b8080c-cd93-4dd0-810c-a8ad2ec617e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BERT model\n",
    "num_labels = 2  # 2 classes for relevance: 1 = relevant, 0 = irrelevant\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # automatically choose GPU if available, otherwise use CPU\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea2ca0d-4760-43ba-b116-a7489c453c9e",
   "metadata": {},
   "source": [
    "Source of code: [transformers_bert_classification_collab.ipynb](https://github.com/uvacw/teaching-bdaca/blob/main/modules/machinelearning-text-exercises/transformers_bert_classification_collab.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86873870-d786-452b-8442-3df2300f350b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"WANDB_MODE\"] = \"offline\"\n",
    "\n",
    "metric_name = \"accuracy\" # you can change this for macro f1 etc\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    # Where to save model + checkpoints\n",
    "    output_dir=\"./results\",\n",
    "\n",
    "    # Training setup\n",
    "    num_train_epochs=4,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_steps=0,\n",
    "    weight_decay=0.01,\n",
    "\n",
    "    # Logging\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=20,\n",
    "\n",
    "    # Evaluation & saving\n",
    "    eval_strategy=\"steps\",   # evaluate every eval_steps\n",
    "    eval_steps=50,\n",
    "    save_st# Initialize BERT model\n",
    "num_labels = 2  # 2 classes for relevance: 1 = relevant, 0 = irrelevant\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # automatically choose GPU if available, otherwise use CPU\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels).to(device)rategy=\"steps\",   # save checkpoint every save_steps\n",
    "    save_steps=50,\n",
    "\n",
    "    # Best-model loading\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    "    greater_is_better=True,\n",
    "\n",
    "    # Run on CPU or GPU automatically (Trainer + accelerate handle this)\n",
    "    # You don't need to set device manually here\n",
    ")\n",
    "\n",
    "# Define metrics\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    labels = p.label_ids\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {'accuracy': acc, 'f1': f1, 'precision': precision, 'recall': recall}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated ü§ó Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=val_dataset,           # evaluation dataset\n",
    "    compute_metrics=compute_metrics      # our custom evaluation function\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cbeb8b-0e57-43c2-b7bd-7b508f2a9eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lock a decision threshold\n",
    "THRESHOLD = 0.35"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b70ba6-1c5b-43de-951b-037976530ace",
   "metadata": {},
   "source": [
    "Wrap the full dataframe into a HuggingFace Dataset object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9402a7-0a18-455c-8d12-528cff22f79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select text for classification\n",
    "df_full = df_comments.copy()\n",
    "\n",
    "texts = df_full[\"clean_comment\"].astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5402ac5f-27c5-4e53-9809-7e4ce5b2fe11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the full dataset with the same tokenizer\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding=True, truncation=True, max_length=128)\n",
    "\n",
    "full_dataset = Dataset.from_dict({\"text\": texts})\n",
    "full_dataset = full_dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f14dafb-eaca-4354-a803-49dce1987a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dataset format for PyTorch\n",
    "full_dataset.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e58bfa-f92b-4867-8347-094659700ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the model to the FULL dataset (6610)\n",
    "# Predict probabilities:\n",
    "preds = trainer.predict(full_dataset)\n",
    "probs = torch.softmax(torch.tensor(preds.predictions), dim=1)[:, 1]\n",
    "# Apply threshold\n",
    "df_comments[\"relevant_pred\"] = (probs >= THRESHOLD).cpu().numpy().astype(int)\n",
    "df_comments[\"relevant_prob\"] = probs.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad82a34a-62e4-4c06-845d-ad6aef1a9b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final check\n",
    "df_comments[\"relevant_pred\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d918f15-3b1d-4aa1-9b0d-37060b6fb42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter relevant comments\n",
    "df_relevant = df_comments[df_comments[\"relevant_pred\"] == 1]\n",
    "print(\"Relevant comments:\", len(df_relevant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f84eb2e-0d3a-49f3-ab88-89f745d5e377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save full dataset with predictions\n",
    "df_comments.to_csv(\"youtube_comments_relevance_trained.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SUe3OaMlMzpM",
   "metadata": {
    "id": "SUe3OaMlMzpM"
   },
   "source": [
    "## Step 2: Agreement Classification (Agree/Neutral/Disagree)\n",
    "### Prepare EXCEL file for step 2 labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Pqvn2brMBu6U",
   "metadata": {
    "id": "Pqvn2brMBu6U"
   },
   "outputs": [],
   "source": [
    "# Load the labeled relevance Excel\n",
    "labeled_relevance = pd.read_excel(\"relevance_label_sample.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e52a7c4-a071-4dcd-9309-f7089fff6a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only the relevant comments\n",
    "relevant_comments = labeled_relevance[labeled_relevance['relevance_label'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43de4445-57d0-47a1-887e-121ea1572e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the comment text and create an empty column for the agreement label\n",
    "step2_comments = relevant_comments[['clean_comment']]\n",
    "step2_comments['agree_label'] = \"\"  # empty for manual labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6796aeb7-4d75-4175-a553-ee4806248356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to Excel for manual labeling\n",
    "step2_comments.to_excel(\"agreement_label.xlsx\", index=False)\n",
    "\n",
    "print(f\"Exported {len(step2_comments)} relevant comments for Step 2 labeling.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815ce79b-81c6-4908-9221-43deec729284",
   "metadata": {},
   "source": [
    "### Run the code below after completing manual labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a9faa3-8e33-4f3a-a233-01bd87f4828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the labled EXCEL file\n",
    "labeled_agree = pd.read_excel(\"agreement_label.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8212e5c-99aa-40da-b359-a488b1eb8cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments_merged1['clean_comment'] = df_comments_merged1['clean_comment'].astype(str)\n",
    "labeled_agree['clean_comment'] = labeled_agree['clean_comment'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61843e1a-58f5-4de6-8794-471afff34a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments_merged1 = df_comments_merged1.drop(columns=['agree_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e9f2de-c551-4053-ba12-1661621c67c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments_merged2 = df_comments_merged1.merge(\n",
    "    labeled_agree,\n",
    "    on=\"clean_comment\",\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfe0b2d-d0b7-4990-9c2b-ba38b154aeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the CSV\n",
    "df_comments_merged2.to_csv(\"youtube_comments_agree_labled.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e165b902-a59c-4510-b9e8-d00eb2efbc15",
   "metadata": {},
   "source": [
    "### Train BERT for step 2 (agreement) classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c168fb-f208-4d8f-a1d8-eab57967dbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep rows with labels for training\n",
    "df_labeled = df_comments_merged2[df_comments_merged2['agree_label'].notna()].copy()\n",
    "print(f\"Labeled comments available for training: {len(df_labeled)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b83730-2f07-475b-8663-37bd51ad4e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns for SML\n",
    "df = df_labeled[['clean_comment', 'agree_label']].dropna()\n",
    "\n",
    "# Ensure label is integer\n",
    "df['agree_label'] = df['agree_label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7687022b-85fa-4072-a1df-6f0d99601d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train, validation, test (e.g., 70-15-15)\n",
    "texts = df['clean_comment'].tolist()\n",
    "labels = df['agree_label'].tolist()\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    texts, labels, test_size=0.15, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=0.1765, random_state=42, stratify=y_train_val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1b078c-ba78-4142-a667-b82ad46da478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Hugging Face Dataset\n",
    "train_dataset = Dataset.from_dict({'text': X_train, 'label': y_train})\n",
    "val_dataset = Dataset.from_dict({'text': X_val, 'label': y_val})\n",
    "test_dataset = Dataset.from_dict({'text': X_test, 'label': y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeed198d-2415-4c83-a528-3516a75bb68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding=True, truncation=True, max_length=128)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize, batched=True)\n",
    "\n",
    "# Set format for PyTorch\n",
    "train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "val_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a504e36b-dd1f-456e-8b49-04a5f99ced6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BERT model\n",
    "num_labels = 3  # 2 classes for agreements: 1 = agree, 0 = neither agree nor disagree, -1 = disagree\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # automatically choose GPU if available, otherwise use CPU\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbbc9aa-a9f9-47ed-aaa0-9332f637246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"agree_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c71fdb3-9c6e-46ab-af46-a68a04194997",
   "metadata": {},
   "source": [
    "Note:\n",
    "- 1 refers to 0 in manual coding (for neither agree nor disagree)\n",
    "- 0 refers to -1 in manual coding (for disagree)\n",
    "- 2 refers to 1 in manual coding (for agree)\n",
    "\n",
    "I applied class weighting to avoid the classification over-favor/learn from the dominant category, which is neither agree nor disagree in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c4d564-97b4-43b4-8667-e5fa641a040f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights\n",
    "labels = df[\"agree_label\"].values\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(labels),\n",
    "    y=labels\n",
    ")\n",
    "\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "print(\"Class weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5eec66-20d2-43ca-b8a1-877b74301219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new trainer with weighted loss\n",
    "class WeightedTrainer(Trainer):\n",
    "    def __init__(self, class_weights, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.class_weights = class_weights.to(self.model.device)\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=self.class_weights)\n",
    "        loss = loss_fct(logits, labels)\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8d28dc-af9f-4e31-afb5-51b4cf4604dd",
   "metadata": {},
   "source": [
    "Source of code: [transformers_bert_classification_collab.ipynb](https://github.com/uvacw/teaching-bdaca/blob/main/modules/machinelearning-text-exercises/transformers_bert_classification_collab.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e7b864-c9b1-48d6-bdae-d4d7f47d6ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"WANDB_MODE\"] = \"offline\"\n",
    "\n",
    "metric_name = \"f1\" # you can change this for macro f1 etc\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    # Where to save model + checkpoints\n",
    "    output_dir=\"./results\",\n",
    "\n",
    "    # Training setup\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=0,\n",
    "    weight_decay=0.01,\n",
    "\n",
    "    # Logging\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=20,\n",
    "\n",
    "    # Evaluation & saving\n",
    "    eval_strategy=\"steps\",   # evaluate every eval_steps\n",
    "    eval_steps=50,\n",
    "    save_strategy=\"steps\",   # save checkpoint every save_steps\n",
    "    save_steps=50,\n",
    "\n",
    "    # Best-model loading\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    "    greater_is_better=True,\n",
    "\n",
    "    # Run on CPU or GPU automatically (Trainer + accelerate handle this)\n",
    "    # You don't need to set device manually here\n",
    ")\n",
    "\n",
    "# Define metrics\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    labels = p.label_ids\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro',zero_division=0)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {'accuracy': acc, 'f1': f1, 'precision': precision, 'recall': recall}\n",
    "\n",
    "trainer = WeightedTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    class_weights=class_weights\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0f29b5-e7e5-4a8e-ba79-fff6a2f69f19",
   "metadata": {},
   "source": [
    "Source of code: [BERTopic_demo.ipynb](https://github.com/uvacw/teaching-bdaca/blob/main/6ec-course/week05/exercises/BERTopic_demo.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44eee831-0f47-4f03-8e6e-98a4115ef384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select text for classification\n",
    "df_full = df_comments.copy() # refers to \"youtube_comments_relevance_trained.csv\"\n",
    "\n",
    "df_relevant = df_comments[df_comments[\"relevant_pred\"] == 1]\n",
    "print(\"Relevant comments:\", len(df_relevant))\n",
    "\n",
    "texts = df_relevant[\"clean_comment\"].astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e334fabc-fbf8-4bce-8b0b-5b5943ab95f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the full dataset with the same tokenizer\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding=True, truncation=True, max_length=128)\n",
    "\n",
    "full_dataset = Dataset.from_dict({\"text\": texts})\n",
    "full_dataset = full_dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ba99f1-1f05-4b11-b728-310e0414b714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dataset format for PyTorch\n",
    "full_dataset.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac4c4a9-0e58-4a12-b866-b72da93a2e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the model to the FULL dataset\n",
    "preds = trainer.predict(full_dataset)  # full_dataset now corresponds to df_relevant\n",
    "logits = torch.tensor(preds.predictions)\n",
    "\n",
    "# Get predicted class IDs (0, 1, or 2)\n",
    "predicted_class_ids = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "\n",
    "# Get softmax probabilities for all classes\n",
    "all_probs = torch.softmax(logits, dim=1).cpu().numpy()\n",
    "\n",
    "# Initialize new columns in df_comments with NaN\n",
    "df_comments[\"agree_pred\"] = np.nan\n",
    "df_comments[\"agree_pred_prob_neg\"] = np.nan\n",
    "df_comments[\"agree_pred_prob_neutral\"] = np.nan\n",
    "df_comments[\"agree_pred_prob_pos\"] = np.nan\n",
    "\n",
    "# Assign predictions to the corresponding rows in df_comments using the index of df_relevant\n",
    "df_comments.loc[df_relevant.index, \"agree_pred\"] = predicted_class_ids\n",
    "df_comments.loc[df_relevant.index, \"agree_pred_prob_neg\"] = all_probs[:, 0]\n",
    "df_comments.loc[df_relevant.index, \"agree_pred_prob_neutral\"] = all_probs[:, 1]\n",
    "df_comments.loc[df_relevant.index, \"agree_pred_prob_pos\"] = all_probs[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a88a6a8-f363-4f77-83bf-b604a50754f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relabel the trained comments to align with the codebook\n",
    "mapping = {0: -1, 1: 0, 2: 1}  # adjust based on your training labels\n",
    "df_comments['agree_pred'] = df_comments['agree_pred'].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a93824-95e6-415b-bd58-35b28b808620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final check\n",
    "df_comments[\"agree_pred\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c63dab-ddec-4dfd-9979-ad500f99a049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save full dataset with predictions\n",
    "df_comments.to_csv(\"youtube_comments_agree_trained.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0304a915-80f4-4057-b06c-6bcd991585d6",
   "metadata": {},
   "source": [
    "### *RQ1: How much do people agree, disagree, or neither agree nor disagree with ‚ÄúIt‚Äôs embarrassing to have a boyfriend now‚Äù?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bed8e2c-bd14-4f27-a63e-af1c5cf401fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments = pd.read_csv(\"youtube_comments_agree_trained.csv\") # delete!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ef1867-6b98-41bc-9d8c-33d457addfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of comments in each predicted category\n",
    "counts = df_comments['agree_pred'].value_counts()\n",
    "print(\"Counts:\\n\", counts)\n",
    "\n",
    "# Calculate the proportions\n",
    "proportions = df_comments['agree_pred'].value_counts(normalize=True)\n",
    "print(\"\\nProportions:\\n\", proportions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf87160-09b7-4076-99fb-f1a316f380f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart\n",
    "colors = ['orange', 'red', 'green']  # Neutral, Disagree, Agree\n",
    "ax = counts.plot(kind='bar', color=colors)\n",
    "plt.xlabel('Type of agreement')\n",
    "plt.ylabel('Number of comments')\n",
    "ax.set_xticks(range(len(counts)))\n",
    "ax.set_xticklabels(['Neutral', 'Disagree', 'Agree'], rotation=0)\n",
    "\n",
    "# Save the figure locally\n",
    "plt.savefig('agreement_bar_chart.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5edadd6-dc0b-4eee-838f-dcdadfaf5bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments.groupby('agree_pred')['comment_likes'].agg(['sum', 'mean', 'max', 'min', 'median', 'std'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0752e2-e456-4ff4-bf59-a838261a8853",
   "metadata": {},
   "source": [
    "## Step 3: \n",
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a47820-9d68-4fc3-9e2e-45f88cb9cb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe for the relevant comments that expressed neither agree nor disagree opinion\n",
    "neutral_df = df_comments[\n",
    "    (df_comments[\"relevant_pred\"] == 1) &\n",
    "    (df_comments[\"agree_pred\"] == 0)\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1d0822-745e-4ba4-b406-20e7c26c04ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization of the clean comments\n",
    "vectorizer_model = CountVectorizer(\n",
    "    stop_words=\"english\",\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=1,      # ignore rare words\n",
    "    max_df=0.85      # ignore very frequent words\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1299b3b7-77d7-4942-9a88-e68f97d109ac",
   "metadata": {},
   "source": [
    "### Train a BERTopic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658e8a39-c176-4d83-a33d-d8f135d132f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SentenceBERT embedding\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842290d0-c605-4380-96ab-8c4c0725a86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the BERTopic model\n",
    "topic_model = BERTopic(\n",
    "    embedding_model=embedding_model,\n",
    "    vectorizer_model=vectorizer_model,\n",
    "    min_topic_size=50,\n",
    "    calculate_probabilities=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "docs = neutral_df['clean_comment'].tolist()\n",
    "topics, probs = topic_model.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cde22bd-26b1-4909-ab43-b549eb2afbf3",
   "metadata": {},
   "source": [
    "### Inspect the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e1ba99-959e-472c-a2d0-1233cc46bf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the topics:\n",
    "topic_info = topic_model.get_topic_info()\n",
    "topic_info.to_csv('bertopic_topic_info.csv', index=False)\n",
    "topic_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe47b18b-80fb-4cc1-abe8-893e44736624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get information for each document:\n",
    "doc_info = topic_model.get_document_info(docs)\n",
    "doc_info.to_csv('bertopic_document_info.csv', index=False)\n",
    "doc_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06495de-9038-4931-b133-00ba9d25521d",
   "metadata": {},
   "source": [
    "### Visualize the results\n",
    "Source of code: [visualization.ipynb](https://github.com/uvacw/teaching-bdaca/blob/main/modules/basics/visualization.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e147d58-3c2b-4653-a5a5-9835d0e86116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart of top keywords\n",
    "fig = topic_model.visualize_barchart(top_n_topics=5)\n",
    "fig.update_layout(title_text='')\n",
    "fig.write_html(\"bertopic_keyword_barchart.html\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c49aeff-fa22-4fc2-ae88-5d7799fd5816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wordcloud overview for each topic\n",
    "topics = topic_model.get_topics()\n",
    "topic_ids = [0, 1, 2, 3] # exlcude topic -1\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, topic_id in zip(axes, topic_ids):\n",
    "    words = topics[topic_id]\n",
    "    word_freq = {word: weight for word, weight in words}\n",
    "\n",
    "    wc = WordCloud(\n",
    "        width=600,\n",
    "        height=400,\n",
    "        background_color='white',\n",
    "        max_words=30\n",
    "    ).generate_from_frequencies(word_freq)\n",
    "\n",
    "    ax.imshow(wc, interpolation='bilinear')\n",
    "    ax.set_title(f'Topic {topic_id}', fontsize=12)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save locally\n",
    "plt.savefig(\n",
    "    'neutral_topics_wordcloud.png',\n",
    "    dpi=300,\n",
    "    bbox_inches='tight'\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
